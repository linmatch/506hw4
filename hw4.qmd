---
title: "hw4"
author: "Manqing Lin"
format:
  html:
    embed-resources: true
editor: visual
---

## Problem1

```{r}
#install.packages("nycflights13")
library(nycflights13)
library(tidyverse)
#View(airports)
#View(flights)
#View(planes)
```

##a

```{r}
##pipe the data and group it by different airport, then get the mean and median of depature delay of each airport and report it in a descending order by mean
df1<-flights %>% group_by(origin) %>% summarize(mean_dep_delay = mean(dep_delay,na.rm = TRUE), median_dep_delay=median(dep_delay,na.rm = TRUE))%>%arrange(desc(mean_dep_delay))

df1
```

```{r}
##subset the data and keep only those row which destination has more than 10 flights
newflights<-flights%>%group_by(dest)%>%filter(n()>=10)%>%ungroup()

##pipe the new data and group it by the airports, then get the mean and median of arrival delay of each airport and report it in a descending order by mean
df2<-newflights %>% group_by(origin) %>% summarize(mean_arrive_delay = mean(arr_delay,na.rm = TRUE), median_arrive_delay=median(arr_delay,na.rm = TRUE))%>%arrange(desc(mean_arrive_delay))

df2
```

##b

```{r}
##join two dataset
newdata<-merge(planes,flights, by="tailnum")

##pipe new data set and group it by model name, get the average speed of planes using the distance and the airtime, also get the number of flights of the given plane, then display the model with the highest average speed and its corresponding number of flights.
df3<- newdata %>%group_by(model) %>%summarise(avg_speed = mean(distance / air_time * 60, na.rm = TRUE),num_flights = n())%>%arrange(desc(avg_speed))

df3[1,]
```

## Problem2

```{r}
library(readr)
nnmaps <- read_csv("~/Desktop/chicago-nmmaps.csv")
View(nnmaps)
```

```{r}
##function that allow a user to get the average temperture for a given month
get_temp <- function(month, year, data, celsius=FALSE, average_fn=mean){
##get the corresponding data for a given month and year
  row<-nnmaps%>%filter(month==month, year==year)
##Check if the data is empty, if empty, then stop further execution
  if(is_empty(row)){
    stop("Data is not available for the given month and year")
  }
##get the average temperature for the given month and year
  avg_temp<-row%>%summarise(avg_temp=average_fn(temp, na.rm = TRUE))%>%pull(avg_temp)
##convert the temperature into celsius if TRUE  
  if(celsius){
    avg_temp<-(avg_temp-32)*(5/9)
  }
  
  return(avg_temp)
}
```

```{r}
get_temp("Apr", 1999, data = nnmaps)
```

```{r}
get_temp("Apr", 1999, data = nnmaps, celsius = TRUE)
```

```{r}
get_temp(10, 1998, data = nnmaps, average_fn = median)
```

```{r}
get_temp(13, 1998, data = nnmaps)
```

```{r}
get_temp(2, 2005, data = nnmaps)
```

```{r}
get_temp("November", 1999, data =nnmaps, celsius = TRUE,
         average_fn = function(x) {
           x %>% sort -> x
           x[2:(length(x) - 1)] %>% mean %>% return
         })
```

## Problem3

**SAS:**

/\*get the data of recs2020\*/

LIBNAME mydata '\~/my_shared_file_links/jbhender0/output_data/';

RUN;

DATA work.recs2020;

SET mydata.recs2020;

RUN;

**/\*a\*/**

/\*get a frequency table of state and order it by frequency\*/

PROC FREQ data=work.recs2020 ORDER=freq;

	TABLES state_name/OUT=state_freq;

	WEIGHT NWEIGHT;

RUN;

/\*find out the frequency of Michigan\*/

DATA MI_percentage;

	SET state_freq;

	WHERE state_name='Michigan';

RUN;

/\*display the percentage of Michigan\*/

PROC PRINT DATA=MI_percentage;

RUN;

**/\*b\*/**

/\*set the name of the histogram\*/

TITLE 'Histogram of total electricity cost in dollar';

/\*produce a histogram of total electricity cost in dollar\*/

PROC UNIVARIATE DATA=work.recs2020;

/\*use corresponding variable "DOLLAREL"\*/

VAR DOLLAREL;

HISTOGRAM DOLLAREL;

/\*only include the value of total cost that is positive\*/

WHERE DOLLAREL \> 0;

RUN;

**/\*c\*/**

/\*transform the value of total electricity cost to log value\*/

DATA recs2020;

SET work.recs2020;

logTotalDol = LOG(DOLLAREL);

WHERE DOLLAREL \> 0;

RUN;

/\*set the name of the histogram\*/

TITLE 'Histogram of log total electricity cost in dollar';

PROC SGPLOT DATA=recs2020;

/\*produce a histogram of log total electricity cost in dollar\*/

HISTOGRAM logTotalDol / FILLATTRS=graphdata1;

RUN;

**/\*d\*/**

/\*fit a linear regression model with response of log cost and predictors of

number of rooms and whether have garage\*/

PROC REG DATA=work.recs2020;

	MODEL logTotalDol = BEDROOMS PRKGPLC1;

	WEIGHT NWEIGHT;

RUN;

**/\*e\*/**

/\*fit a linear regression model with response of cost and predictors of

number of rooms and whether have garage\*/

PROC GLM DATA=work.recs2020;

	MODEL DOLLAREL = BEDROOMS PRKGPLC1 / SOLUTION;

	WEIGHT NWEIGHT;

/\*get the predicted value of total cost\*/

	OUTPUT OUT=pred_values predicted=predCost;

RUN;

	

/\*Generate a scatterplot of Predicted and Actual Total Electricity Cost\*/

PROC SGscatter DATA=pred_values;

	PLOT DOLLAREL\*predCost;

TITLE "Scatterplot of Predicted vs Actual Total Electricity Cost";

RUN;

## Problem4

**SAS:**

**/\*a\*/**

The code book is generated by variables from the survey, including type, range, unique value, mean, standard deviation and percentiles of each variable. It also indicate the number of missing value.

**/\*b\*/**

/\*import the data\*/

FILENAME REFFILE '/home/u63642415/public2022.csv';

PROC IMPORT DATAFILE=REFFILE

	DBMS=CSV

	OUT=WORK.IMPORT;

	GETNAMES=YES;

RUN;

PROC CONTENTS DATA=WORK.IMPORT;

RUN;

**/\*c\*/**

/\*select the necessary data of interest and generate a new dataset\*/

PROC sql;

	CREATE TABLE data_interest AS

	SELECT B3, B7_a, B7_b, GH1, educ_4cat, race_5cat

	FROM WORK.IMPORT;

RUN;	

/\*export the new dataset as a csv file\*/

PROC EXPORT DATA=data_interest

OUTFILE='/home/u63642415/sasuser.v94/DATA_INTEREST.csv';

DBMS=DTA REPLACE;

RUN;

**STATA:**

``` stata
/d/
. import delimited "/Users/linmatch/Desktop/DATA_INTEREST.csv"
(encoding automatically selected: UTF-8)
(8 vars, 11,667 obs)

. save "/Users/linmatch/Desktop/DATA_INTEREST.csv", replace
file /Users/linmatch/Desktop/DATA_INTEREST.csv saved as .dta format

. use "/Users/linmatch/Desktop/DATA_INTEREST.csv", clear

. describe

Contains data from /Users/linmatch/Desktop/DATA_INTEREST.csv
 Observations:        11,667                  
    Variables:             8                  22 Oct 2023 12:16
--------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------
caseid          int     %8.0g                 CaseID
weight_pop      float   %9.0g                 
b3              str19   %19s                  B3
nd2             str15   %15s                  ND2
b7_b            str9    %9s                   B7_b
gh1             str57   %57s                  GH1
educ_4cat       str43   %43s                  
race_5cat       str8    %9s                   
--------------------------------------------------------------------------------------------
Sorted by: 

. rename(weight_pop b3 nd2 b7_b gh1 educ_4cat race_5cat)(weightpop Financial_cond Weather_co
> nd Country_econ_rate Whether_mortgage Education Race)

. 
```

``` stata
/e/
. gen FinancialOutcome = (Financial_cond == "Somewhat worse off")

. list FinancialOutcome in 1/5

     +----------+
     | Financ~e |
     |----------|
  1. |        0 |
  2. |        0 |
  3. |        0 |
  4. |        1 |
  5. |        1 |
     +----------+

.
```

``` stata
/f/
. svyset caseid [pw=weightpop]

Sampling weights: weightpop
             VCE: linearized
     Single unit: missing
        Strata 1: <one>
 Sampling unit 1: caseid
           FPC 1: <zero>

. encode Education, generate(neweduc)

. encode Race, generate(newrace)

. encode Weather_cond, generate(newWeather_cond)

. encode Country_econ_rate, generate(newCountry_rate)

. encode Whether_mortgage, generate(newMortgage)

.  svy: logistic FinancialOutcome i.newrace i.neweduc i.newWeather_cond i.newCountry_rate i.
> newMortgage
(running logistic on estimation sample)

Survey: Logistic regression

Number of strata =      1                        Number of obs   =      11,667
Number of PSUs   = 11,667                        Population size = 255,114,223
                                                 Design df       =      11,666
                                                 F(17, 11650)    =       25.93
                                                 Prob > F        =      0.0000

-------------------------------------------------------------------------------------------
                          |             Linearized
         FinancialOutcome | Odds ratio   std. err.      t    P>|t|     [95% conf. interval]
--------------------------+----------------------------------------------------------------
                  newrace |
                   Black  |   .8266611    .128146    -1.23   0.219     .6100475    1.120189
                Hispanic  |    1.29168   .1923744     1.72   0.086     .9646496     1.72958
                   Other  |   1.270994   .2745411     1.11   0.267     .8322634    1.941004
                   White  |   1.516173   .2018925     3.13   0.002     1.167862    1.968366
                          |
                  neweduc |
High school degree or ..  |   1.121751   .0720165     1.79   0.074     .9891075    1.272182
Less than a high schoo..  |   1.031476   .1231634     0.26   0.795      .816227    1.303489
Some college/technical..  |   1.094312   .0593716     1.66   0.097     .9839086    1.217104
                          |
          newWeather_cond |
             Much higher  |   .9393502   .0827574    -0.71   0.478     .7903661    1.116418
              Much lower  |   .6240386   .1090404    -2.70   0.007     .4430601    .8789421
         Somewhat higher  |   1.089623   .0610615     1.53   0.126     .9762715    1.216134
          Somewhat lower  |   .7623861   .1533847    -1.35   0.178     .5139297    1.130957
                          |
          newCountry_rate |
                    Good  |   2.496149   .9833842     2.32   0.020     1.153177    5.403126
               Only fair  |   4.756968   1.846558     4.02   0.000     2.222679    10.18084
                    Poor  |   8.957031   3.476679     5.65   0.000     4.185383    19.16871
                          |
              newMortgage |
Own your home free an..)  |   1.752748    .194689     5.05   0.000     1.409812    2.179103
Own your home with a m..  |   1.543524   .1663531     4.03   0.000     1.249584    1.906606
                Pay rent  |   1.447053   .1625549     3.29   0.001      1.16106    1.803492
                          |
                    _cons |   .0299636   .0125545    -8.37   0.000     .0131798    .0681206
-------------------------------------------------------------------------------------------
Note: _cons estimates baseline odds.

. 

Accordding to the outcome above, we can observe that only the odds ratio of "Much lower" in "newWeather_cond" is statistically significant since the p-value is 0.007 which is smaller than alpha=0.05. Therefore, we can conclude that people who believe the chance of experiencing a natural disaster or severe weather event will be "Much lower"in 5 years are associated with lower odds of reportiing a "worse off" financial condition.

. export delimited using "/Users/linmatch/Desktop/exported_data.csv", replace
(file /Users/linmatch/Desktop/exported_data.csv not found)
file /Users/linmatch/Desktop/exported_data.csv saved
```

##g

```{r}
#library(readr)
exported_data <- read_csv("~/Desktop/exported_data.csv")
#View(exported_data)
#install.packages("survey")
library(DescTools)
#library(survey)
```

##h

```{r}
design<-svydesign(id = ~ caseid, weight = ~ weightpop, data = exported_data)
```

```{r}
model<-svyglm(FinancialOutcome ~ newWeather_cond + newrace+neweduc+newCountry_rate+newMortgage,design=design, family=quasibinomial())

psrsq(model)
```
